[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "llama-ai-app"
version = "0.1.0"
description = "A professional LLM integration package using Llama 3 via Groq"
readme = "README.md"
requires-python = ">=3.12"
authors = [
  { name = "Your Name", email = "your.email@university.edu" }
]

dependencies = [
  "groq>=0.15.0",
  "python-dotenv",
  "typing-extensions>=4.13.2",

  # OCR (หลัก - local)
  "opencv-python",
  "Pillow",
  "pytesseract",
  "numpy",

  # OCR (Azure - primary)
  "azure-ai-vision-imageanalysis>=1.0.0",
  "azure-core>=1.30.0",
]

[project.optional-dependencies]
# ติดตั้งเพิ่มเฉพาะตอนอยากใช้ fallback แบบ local (EasyOCR)
ocr_easy = [
  "easyocr",
]

[project.scripts]
ai-start = "ai.analysis:main"

[tool.setuptools.packages.find]
where = ["."]
include = ["ai*"]
